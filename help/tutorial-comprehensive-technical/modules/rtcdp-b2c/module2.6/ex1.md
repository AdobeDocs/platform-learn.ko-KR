---
title: Apache Kafka 소개
description: Apache Kafka 소개
kt: 5342
doc-type: tutorial
source-git-commit: 2cdc145d7f3933ec593db4e6f67b60961a674405
workflow-type: tm+mt
source-wordcount: '1003'
ht-degree: 0%

---

# 2.6.1 Apache Kafka 소개

## 2.6.1.1 소개

모든 조직은 데이터 관점에서 매우 간단한 방식으로 시작합니다. 조직의 데이터 에코시스템은 하나의 소스 시스템과 하나의 타겟으로 시작됩니다. 소스 시스템은 데이터를 타겟 시스템으로 전송합니다. 진정해, 그렇지?
그렇게 단순하기만 하면 됩니다. 조직은 이러한 단순한 설치보다 빠르게 증가하고 소스 시스템과 타겟 시스템의 수는 빠르게 증가합니다. 이렇게 서로 다른 모든 소스와 대상은 서로 데이터를 교환해야 하며 상황은 빠르게 매우 복잡해집니다.
예를 들어 조직에 4개의 소스와 6개의 대상이 있고 이러한 모든 애플리케이션이 서로 이야기해야 하는 경우 24개의 통합을 구축해야 합니다. 이러한 각 통합에는 고유한 어려움이 있습니다.

- 프로토콜: 데이터 전송 방식(TCP, HTTP, REST, FTP, ...)
- 데이터 형식: 데이터를 구문 분석하는 방법(바이너리, CSV, JSON, Parquet 등)
- 데이터 스키마와 진화: 데이터 모델은 무엇이며 어떻게 진화합니까?

또한 소스 시스템을 대상 시스템에 연결할 때마다 해당 연결에서 해당 시스템에 대한 로드가 증가합니다.

그럼, 어떻게 해결할까요? 바로 아파치 카프카가 이 사진에 나타난 곳입니다. Apache Kafka를 사용하면 조직에서 공통, 높은 처리량의 분산 메시징 시스템을 제공하여 데이터 스트림과 시스템을 분리할 수 있습니다. Source 시스템은 데이터를 Apache Kafka로 전송하고 대상 시스템은 Apache Kafka의 데이터를 사용합니다.

experience business에서 관리해야 하는 모든 유형의 데이터 소스를 생각해 보십시오.

- 웹 사이트 이벤트
- 모바일 앱 이벤트
- POS 이벤트
- CRM 데이터
- 콜센터 데이터
- 거래 내역
- ...

또한 비즈니스가 에코시스템에서 사용하는 모든 유형의 대상, 즉 소스 시스템의 데이터가 필요할 수 있는 모든 대상을 생각해 보십시오.

- CRM
- 데이터 레이크
- 이메일 시스템
- 감사
- analytics
- ...

Apache Kafka는 LinkedIn에서 만들었으며 현재 주로 Confluent에서 유지 관리하는 오픈 소스 프로젝트입니다.
Apache Kafka는 내결함성이 있는 배포되고 복원력이 뛰어난 아키텍처를 제공합니다. 100개의 중개업체로 가로로 확장할 수 있으며 초당 수백만 개의 메시지로 확장할 수 있습니다. 10ms 미만의 지연 시간으로 높은 성능을 제공하여 실시간 사용 사례에 이상적입니다.

두 가지 사용 사례 예:

- 메시징 시스템
- 활동 추적
- 다양한 위치에서 지표 수집
- 애플리케이션 로그 수집
- 스트림 처리(Kafka Streams API 또는 Spark 사용)
- 시스템 종속성 분리
- Spark, Flink, Storm, Hadoop 및 기타 여러 빅 데이터 기술과 통합됩니다.

예:

- 넷플릭스가 카프카를 활용해 TV프로그램을 보는 동안 실시간으로 추천프로그램을 적용한다
- 우버는 Kafka를 사용하여 사용자, 택시 및 여행 데이터를 실시간으로 수집하고 수요를 계산 및 예측하며 급등한 가격을 실시간으로 계산합니다
- LinkedIn은 Kafka를 사용하여 스팸을 방지하고, 사용자 상호 작용을 수집하여 실시간으로 더 나은 연결 추천을 제공합니다

이 모든 사용 사례에 대해 Kafka는 운송 메커니즘으로만 사용됩니다. Kafka는 애플리케이션 간 데이터 이동에 능숙합니다.

## 2.6.1.2 Kafka 용어

### 메시지

메시지는 시스템에서 Kafka로 보내는 커뮤니케이션입니다. 메시지는 페이로드를 포함하며 페이로드는 데이터 요소를 포함한다. 예를 들어 웹 사이트에서 Adobe Experience Platform으로 전송하는 경험 이벤트는 메시지로 간주됩니다.

### 주제, 분할 영역, 오프셋

주제는 데이터베이스의 테이블과 유사한 데이터의 특정 스트림입니다. 원하는 만큼 주제를 가질 수 있으며 주제는 해당 이름으로 식별됩니다. 주제는 분할 영역에서 분할됩니다. 각 파티션의 순서가 지정되고 파티션 내의 각 메시지에 증분 ID가 있습니다. 이를 **offset**&#x200B;이라고 합니다. 메시지는 주제, 파티션 또는 오프셋을 사용하여 참조됩니다. 메시지는 제한된 시간 동안만 유지됩니다(기본값은 1주). 파티션에 메시지가 기록되면 더 이상 변경할 수 없습니다.

### 중개인

브로커는 서버와 유사합니다. Kafka 클러스터는 여러 브로커(서버)로 구성됩니다. 각 브로커는 ID로 식별되며 특정 주제 파티션을 포함합니다.

### 복제

Kafka는 분산 시스템입니다. 분산 시스템의 중요한 사항 중 하나는 데이터가 안전하게 저장되므로 복제가 필요하다는 것입니다. 결국 한 브로커(서버)가 작동 중지되어도 다른 브로커(서버)는 작동 중지된 브로커에 처음 저장된 메시지에 대한 액세스를 제공할 수 있어야 합니다. 복제는 여러 브로커에 걸쳐 메시지 사본을 만들어 데이터가 손실되지 않도록 합니다.

### 프로듀서

데이터가 Kafka에 어떻게 전송됩니까? 그게 바로 프로듀서의 역할이죠. 프로듀서는 소스 시스템에 연결하여 소스 시스템에서 데이터를 가져온 다음 해당 데이터를 주제에 파티션에 기록합니다. Kafka 클러스터의 구성에 따라 생산자는 어떤 브로커와 파티션을 작성할지 자동으로 알 수 있습니다. 여러 브로커와 복제 전략이 있는 분산 시스템에서 생산자는 여러 브로커에 무작위로 데이터를 저장하게 되는데, 이는 로드 밸런싱을 자동으로 수행한다는 의미입니다.

### 메시지 키

제작자는 메시지가 담긴 키를 보내도록 선택할 수 있다. 키는 문자열, 숫자 등이 될 수 있습니다. 키를 제공하지 않으면 브로커에게 무작위로 메시지가 전송됩니다. 키를 전송하면 해당 키에 대한 모든 메시지가 항상 동일한 파티션으로 이동합니다. 이와 같은 메시지 키는 특정 필드를 기반으로 메시지를 정렬하는 데 사용됩니다.

### 소비자

소비자는 Apache Kafka 항목에서 데이터를 읽은 다음 대상 시스템과 해당 데이터를 공유합니다. 소비자는 어떤 브로커에게 읽어야 하는지 알고 있다. 데이터는 각 파티션 내에서 소비자가 순서대로 읽습니다. 소비자는 소비자 그룹에서 데이터를 읽습니다.

### Zookeeper

ZooKeeper는 기본적으로 계층적 키-값 저장소를 제공하는 분산 시스템을 위한 서비스로서, 대규모 분산 시스템을 위한 분산 구성 서비스, 동기화 서비스 및 이름 지정 레지스트리를 제공하는 데 사용됩니다. Apache Kafka를 사용하려면 먼저 Zookeeper가 실행되어야 하며, Kafka가 이벤트를 생성하고 소비하는 동안 Zookeeper는 백엔드에서 분산 서비스를 관리하는 Kafka에 대한 식의 달인입니다.

이 연습을 완료했습니다.

다음 단계: [2.6.2 Kafka 클러스터 설치 및 구성](./ex2.md)

[모듈 2.6으로 돌아가기](./aep-apache-kafka.md)

[모든 모듈로 돌아가기](../../../overview.md)
