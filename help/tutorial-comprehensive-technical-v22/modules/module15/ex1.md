---
title: Apache Kafka 소개
description: Apache Kafka 소개
kt: 5342
audience: Data Engineer, Data Architect, Data Analyst
doc-type: tutorial
activity: develop
exl-id: 7b600c79-03c5-46fc-9ac9-a15599608c35
source-git-commit: cc7a77c4dd380ae1bc23dc75608e8e2224dfe78c
workflow-type: tm+mt
source-wordcount: '992'
ht-degree: 0%

---

# 15.1 Apache Kafka 소개

## 15.1.1 소개

모든 조직은 데이터 관점에서 매우 간단한 방법으로 시작됩니다. 조직의 데이터 에코시스템은 하나의 소스 시스템과 하나의 타겟으로 시작합니다. 소스 시스템은 데이터를 타겟 시스템으로 전송합니다. 진정해, 그렇지?
그렇게 단순하게 유지된다면. 조직에서는 이러한 간단한 설정과 소스 시스템 및 타겟 시스템의 수를 빠르게 능가하고 있습니다. 이러한 서로 다른 모든 소스와 대상은 데이터를 서로 교환해야 하며 매우 복잡해집니다.
예를 들어, 조직에 4개의 소스와 6개의 대상이 있고 이러한 모든 애플리케이션이 서로 통신해야 하는 경우 24개의 통합을 구축해야 합니다. 이러한 각 통합에는 자체 어려움이 있습니다.

- 프로토콜: 데이터를 전송하는 방법(TCP, HTTP, REST, FTP, ..)
- 데이터 형식: 데이터를 구문 분석하는 방법(이진, CSV, JSON, Parquet, ..)
- 데이터 스키마 및 진화: 데이터 모델은 무엇이며 어떻게 발전합니까?

또한 소스 시스템을 대상 시스템에 연결할 때마다 해당 연결에 있는 시스템의 부하가 증가합니다.

어떻게 해결하죠? 아파치 카프카가 이 사진을 찍은 곳입니다. Apache Kafka를 통해 조직은 통신, 높은 처리량, 분산 메시징 시스템을 제공하여 데이터 스트림 및 시스템을 분리할 수 있습니다. 소스 시스템은 데이터를 Apache Kafka로 전송하고 대상 시스템은 Apache Kafka의 데이터를 사용합니다.

경험 기업이 관리해야 하는 모든 유형의 데이터 소스를 생각해 보십시오.

- 웹 사이트 이벤트
- 모바일 앱 이벤트
- POS 이벤트
- CRM 데이터
- 콜센터 데이터
- 트랜잭션 내역
- ...

그리고 기업이 에코시스템에서 사용하는 모든 유형의 대상에 대해 생각해 보십시오. 이러한 모든 소스 시스템의 데이터가 필요할 수 있습니다.

- CRM
- 데이터 레이크
- 이메일 시스템
- 감사
- analytics
- ...

Apache Kafka는 LinkedIn에서 만들었으며 이제 Confluent에서 주로 유지 관리하는 오픈 소스 프로젝트입니다.
Apache Kafka는 내결함성이 있는 분산 탄력적인 아키텍처를 제공합니다. 가로로 100대의 브로커를 확장할 수 있으며 초당 수백만 개의 메시지로 확장할 수 있습니다. 실시간 사용 사례에 적합한 대기 시간이 10ms 미만인 고성능을 제공합니다.

두 가지 사용 사례 예:

- 메시징 시스템
- 활동 추적
- 다양한 위치에서 지표를 수집합니다
- 애플리케이션 로그 수집
- 스트림 처리(Kafka Streams API 또는 Spark 사용)
- 시스템 종속성 분리
- Spark, Flink, Storm, Hadoop 및 기타 빅데이터 기술과 통합됩니다.

예:

- Netflix에서는 TV 프로그램을 시청하는 동안 Kafka를 사용하여 실시간으로 권장 사항을 적용합니다
- Uber는 Kafka를 사용하여 사용자, 택시 및 여행 데이터를 실시간으로 수집하여 수요 및 예측 및 실시간 컴퓨팅 서지 가격을 산출합니다
- linkedIn은 Kafka를 사용하여 스팸을 방지하고, 사용자 상호 작용을 수집하여 실시간으로 더 나은 연결 추천을 제공합니다

이러한 모든 사용 사례에서 Kafka는 운송 메커니즘으로만 사용됩니다. Kafka는 애플리케이션 간에 데이터를 이동하는 데 매우 유용합니다.

## 15.1.2 Kafka 용어

### 메시지

메시지는 시스템에서 Kafka로 보내는 통신입니다. 메시지에 페이로드가 포함되고 페이로드에 데이터 요소가 포함됩니다. 예를 들어, 웹 사이트에서 Adobe Experience Platform으로 보낸 경험 이벤트는 메시지로 간주됩니다.

### 항목, 파티션, 오프셋

항목은 데이터베이스의 테이블과 유사한 특정 데이터 스트림입니다. 원하는 만큼 주제를 가질 수 있으며 주제는 이름으로 식별됩니다. 항목은 파티션으로 분할됩니다. 각 파티션은 정렬되며 파티션 내의 각 메시지는 **오프셋**. 메시지는 주제, 파티션 등에 저장되며 오프셋을 사용하여 참조됩니다. 메시지는 제한된 시간 동안만 보관됩니다(기본값은 1주). 파티션에 메시지를 쓴 후에는 더 이상 변경할 수 없습니다.

### 브로커

브로커는 서버와 유사합니다. Kafka 클러스터는 여러 브로커(서버)로 구성됩니다. 각 브로커는 ID로 식별되며 특정 항목 파티션을 포함합니다.

### 복제

Kafka는 분산 시스템입니다. 분산 시스템의 중요한 사항 중 하나는 데이터가 안전하게 저장되므로 복제가 필요하다는 것입니다. 결국, 하나의 브로커(서버)가 다운되면 다른 브로커(서버)가 다운된 브로커에 처음에 저장된 메시지에 액세스할 수 있어야 합니다. 복제에서는 데이터가 손실되지 않도록 보장하기 위해 여러 브로커 간에 메시지 사본을 만듭니다.

### 프로듀서

데이터를 Kafka로 전송하는 방법 그것이 프로듀서의 역할입니다. 생성자는 소스 시스템에 접속하여 소스 시스템에서 데이터를 가져온 다음 해당 데이터를 항목에 씁니다. Kafka 클러스터의 구성에 따라 생산자는 작성할 브로커 및 파티션을 자동으로 알게 됩니다. 여러 브로커 및 복제 전략을 사용하는 분산 시스템에서, 생성자는 여러 브로커 간에 데이터를 임의로 저장하므로 로드 밸런싱을 자동으로 수행합니다.

### 메시지 키

제작자는 메시지가 포함된 키를 보내도록 선택할 수 있습니다. 키는 임의의 문자열, 숫자 등이 될 수 있습니다. 제공된 키가 없으면 브로커에게 메시지가 임의로 전송됩니다. 키가 전송되면 해당 키의 모든 메시지는 항상 동일한 파티션으로 이동합니다. 이와 같은 메시지 키는 특정 필드를 기반으로 메시지를 주문하는 데 사용됩니다.

### 소비자

소비자는 Apache Kafka 항목에서 데이터를 읽은 다음 대상 시스템과 해당 데이터를 공유합니다. 소비자는 읽을 브로커를 알고 있습니다. 각 파티션 내에서 소비자가 데이터를 순서대로 읽습니다. 소비자는 소비자 그룹에서 데이터를 읽습니다.

### Zookeeper

동물원은 계층적 키-값 저장소를 제공하는 분산 시스템에 대한 서비스로서, 분산 구성 서비스, 동기화 서비스 및 대규모 분산 시스템에 대한 이름 지정 레지스트리를 제공하는 데 사용됩니다. Apache Kafka를 사용하려면 먼저 Zokeeper를 실행해야 하며 Zokeeper는 Kafka에서 이벤트를 생성하고 소비하는 동안 백엔드에서 분산 서비스를 관리하는 Kafka의 일종의 의식입니다.

너는 이 운동을 끝마쳤다.

다음 단계: [15.2 Kafka 클러스터 설치 및 구성](./ex2.md)

[모듈 15로 돌아가기](./aep-apache-kafka.md)

[모든 모듈로 돌아가기](../../overview.md)
